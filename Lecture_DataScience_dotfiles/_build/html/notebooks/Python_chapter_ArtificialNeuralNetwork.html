
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>機械学習: ニューラルネットワークによる回帰 &#8212; 実践データサイエンス</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="ベイズ最適化による実験計画法" href="Python_chapter_BayesianOptimization.html" />
    <link rel="prev" title="Numpyについて" href="Python_misc_numpy.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">実践データサイエンス</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="この本を検索..." aria-label="この本を検索..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   資料:実践データサイエンス
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  プログラムの実行方法
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter0_HowToUse.html">
   Google Colaboratoryの使い方
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  練習帳
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Python_practice.html">
   練習帳
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pythonの基本文法
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter1_Introduction.html">
   1. Pythonの基本 その１:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter2_ListLoop.html">
   2. Pythonの基本 その２:
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter3_Function.html">
   3. 関数
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ライブラリと可視化
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter4_Matplotlib.html">
   4. ライブラリ/パッケージ/モジュールとデータの可視化(Matplotlib)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  データ分析の基礎
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter5_Probability.html">
   5. 確率と疑似乱数
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter6_Regression.html">
   6. 相関・回帰分析
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter7_Optimization.html">
   7. 最適化問題の基礎
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter8_handling_files.html">
   8. ファイル・文字列操作
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tips&amp;環境構築
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_Error.html">
   よくあるエラー集
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_python_environment.html">
   Pythonの環境構築
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_python_env_forWin11.html">
   Pythonの環境構築 (Windows11版)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_VScode.html">
   コードの編集環境とGitHub Copilot
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  おまけ
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_Pandas.html">
   Pandasの使い方 (基礎)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_numpy.html">
   Numpyについて
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   機械学習: ニューラルネットワークによる回帰
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter_BayesianOptimization.html">
   ベイズ最適化による実験計画法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter_Bayesian_linear_regression.html">
   ベイズ線形回帰
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_StyleGAN3.html">
   StyleGAN3+CLIPによる写真生成
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_chapter_WebScraping.html">
   Web操作・スクレイピング
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_ODE.html">
   常微分方程式の数値解法
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_PCA.html">
   主成分分析
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_SingularValueDecomposition.html">
   特異値分解と情報削減
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Python_misc_NewtonsMethod.html">
   ニュートン法によるN次元多項式の求根
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="ナビゲーションを切り替え" aria-controls="site-navigation"
                title="ナビゲーションを切り替え" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="このページをダウンロード"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/Python_chapter_ArtificialNeuralNetwork.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="ソースファイルをダウンロード" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="PDFに印刷"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/SotaYoshida/Lecture_DataScience"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="ソースリポジトリ"><i
                    class="fab fa-github"></i>リポジトリ</button></a>
        <a class="issues-button"
            href="https://github.com/SotaYoshida/Lecture_DataScience/issues/new?title=Issue%20on%20page%20%2Fnotebooks/Python_chapter_ArtificialNeuralNetwork.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="問題を開く"><i class="fas fa-lightbulb"></i>未解決の問題</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="全画面モード"
        title="全画面モード"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/SotaYoshida/Lecture_DataScience/blob/main/notebooks/Python_chapter_ArtificialNeuralNetwork.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="発売 Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> 目次
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   データの下処理
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   勾配降下法
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#adam">
   Adam
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   最適化手法に関するまとめ
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <p><a href="https://colab.research.google.com/github/SotaYoshida/Lecture_DataScience/blob/main/notebooks/Python_chapter_ArtificialNeuralNetwork.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></p>
<div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>機械学習: ニューラルネットワークによる回帰<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>この章では、最も単純な、入力層・隠れ層・出力層からなるニューラルネットワークを使って、データから尤もらしい予測を与える関数を構築してみましょう。</p>
<p>対象とする(疑似)データは、多項式回帰の際に用いたデータと同じsin関数＋ノイズで生成することにします。</p>
<ul class="simple">
<li><p>すすんだ注: このノートブックでは「ニューラルネットワークをPythonで表現してみる」ことに重きをおくため、使用するデータを訓練データ,検証データ,テストデータに分けることはせず、データは全てニューラルネットワークの訓練データとして使うこととします。
授業で説明するとおり、一般に[教師あり学習]の文脈でニューラルネットワークを考える際は、本来データを上の様に複数用途に分けながら、モデル選択を行ったり、汎化性能の評価に使ったりします。</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="k">def</span> <span class="nf">create_toy_data</span><span class="p">(</span><span class="n">sample_size</span><span class="p">,</span> <span class="n">std</span><span class="p">):</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span> <span class="c1">#毎回同じデータになるように乱数の種を固定しておく </span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">sample_size</span><span class="p">)</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">std</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>                                                                                                                 
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span>

<span class="n">xt</span><span class="p">,</span><span class="n">yt</span> <span class="o">=</span> <span class="n">create_toy_data</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span><span class="mf">5.e-2</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">###グラフにしてみる</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Data&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Python_chapter_ArtificialNeuralNetwork_4_0.png" src="../_images/Python_chapter_ArtificialNeuralNetwork_4_0.png" />
</div>
</div>
<p>ではいくつか必要な関数を適宜定義しながら進めていきましょう。</p>
<p>*注: 以下のコードは入力・出力ともに1次元かつ、決まったニューラルネットワーク構造の場合に対して書かれているため、naiveに2層以上の隠れ層を持つニューラルネットワークに拡張するのはstraightfowardではなく、また効率的ではありません。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nhl</span> <span class="o">=</span> <span class="mi">8</span> <span class="c1">## 隠れ層のノードの数を指定 これを増やすほどニューラルネットワークの表現能力が上がる一方、データに過適合しやすくなる(例外あり)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#重み行列W,V(今はベクトル)と、隠れ層でのバイアスbs,出力層でのバイアスを正規乱数で初期化</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>  <span class="c1">#結果が実行ごとに同じになるよう乱数を固定(バグを見つけやすくする)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">bs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>隠れ層で作用させる活性化関数を定義しておきましょう。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">#シグモイド関数: 活性化関数の一つ</span>
<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>最適化したい量(データとモデルの齟齬を表す量)を目的関数(target function)やloss functionなどと呼びます。(以下でもそれに倣う)</p>
<p>以下では、データとANNのアウトプットの二乗誤差を目的関数として定めることにします。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">### データとANNの出力間の二乗誤差を計算する関数を作っておく。</span>
<span class="k">def</span> <span class="nf">calc_tloss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">):</span>
    <span class="n">nhl</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">tW</span><span class="p">)</span>
    <span class="n">s</span><span class="o">=</span><span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
        <span class="n">s</span> <span class="o">+=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tV</span><span class="p">,</span> <span class="n">acf</span><span class="p">(</span><span class="n">tW</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">tbs</span><span class="p">))</span> <span class="o">+</span> <span class="n">tb0</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">s</span>
</pre></div>
</div>
</div>
</div>
<p>上ではcalc_tlossの引数にacfという変数を指定し、acfにsigmoidを指定しました。<br />
この様にしておくと、sigmoid関数以外の活性化関数を使う際にも、上のcalc_tloss関数が使いまわせますね。</p>
<div class="section" id="id2">
<h2>データの下処理<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>機械学習などの分析では、データの値を中心0,分散1に変換して扱うのが基本です。</p>
<p>このことを、データの標準化と呼びます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ymean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">yt</span><span class="p">)</span>
<span class="n">ystd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">yt</span><span class="p">)</span>
<span class="n">ny</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">yt</span><span class="p">)</span><span class="o">-</span><span class="n">ymean</span><span class="p">)</span><span class="o">/</span> <span class="n">ystd</span> <span class="c1">#それぞれのデータを平均をひいて標準偏差で割る</span>
</pre></div>
</div>
</div>
</div>
<p>なぜ標準化が必要なのかは、今のような1次元入力データの場合よりもむしろ多変数を扱う際を考えてみるとわかります。</p>
<p>変数ごとに標準的なスケールが違う値を扱う場合、スケールの大きな量に学習が引っ張られる、ということが起こりえます。</p>
<p>たとえば目的関数を[体重と身長、それぞれについての二乗誤差の和]とする場合、<br />
データが50kg、ニューラルネットワークの予測が55kgで10%違っていても、二乗誤差の値は25ですが、<br />
身長が180cm vs 198cmと10%違っていたら、二乗誤差の値は324となります。<br />
したがって、目的関数は身長の予測精度により強く依存することになり、<br />
身長をより重視する(きちんと再現する)方向へ、ニューラルネットワークの学習が引っ張られてしまいます。</p>
<p>もちろん、身長をより高い精度で推測したいニューラルネットワークを構築したいなら話は別ですが、<br />
特定の値を特別視しない(全ての量を平等に扱う)のなら、通常は標準化を行います。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acf</span> <span class="o">=</span> <span class="n">sigmoid</span> <span class="c1">#sigmoid関数をacfという名前で使う</span>
</pre></div>
</div>
</div>
</div>
<p>さて、初期値W,V,bs,b0と活性化関数にsigmoidを選んだニューラルネットワークとデータの値の二乗誤差は…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;初期値での二乗誤差&quot;</span><span class="p">,</span><span class="n">calc_tloss</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>初期値での二乗誤差 61.29358546868393
</pre></div>
</div>
</div>
</div>
<p>データ1個あたり、ニューラルネットワークとデータ値との間にどれくらい誤差があるかというと…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;データ1個あたりの誤差:&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">calc_tloss</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">xt</span><span class="p">)))</span> <span class="c1">#データ1個あたりどれほど誤差*があるか *標準化された誤差</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>データ1個あたりの誤差: 1.2378770684995737
</pre></div>
</div>
</div>
</div>
<p>ランダムに生成した重み(W,V)やバイアス項(bs,b0)では、まだニューラルネットワークは訓練がなされていないデタラメな関数なので、図にプロットしてみると…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mi">300</span><span class="p">)</span>
<span class="n">yp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">W</span><span class="o">*</span><span class="n">xp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">bs</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xp</span><span class="p">))])</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Data&quot;</span><span class="p">)</span> 
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">yp</span><span class="o">*</span><span class="n">ystd</span><span class="o">+</span><span class="n">ymean</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;ANN&quot;</span><span class="p">)</span> <span class="c1">#ニューラルネットワークの予測ypは、&quot;標準化された&quot;yの値に従って学習されているので、元のスケールに戻さないといけない。</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Python_chapter_ArtificialNeuralNetwork_22_0.png" src="../_images/Python_chapter_ArtificialNeuralNetwork_22_0.png" />
</div>
</div>
<p>当然ですが、全然だめですね。</p>
<p>状況を改善するためにニューラルネットワークのパラメータを徐々に更新(学習)していきましょう。<br />
そのためには、まず勾配を計算する関数を用意しておきます。</p>
<p>loss functionを<span class="math notranslate nohighlight">\(f\)</span>と書くことにすると、必要な勾配は4種類で
<span class="math notranslate nohighlight">\(\frac{\partial f}{\partial W}, \frac{\partial f}{\partial V}, \frac{\partial f}{\partial b}, \frac{\partial f}{\partial b_0}\)</span>です。<br />
プログラムではそれぞれ<code class="docutils literal notranslate"><span class="pre">dw,dv,dbs,db0</span></code>とでも名前をつけることにして、勾配を返り値として与える関数を定義します。</p>
<p>以下では、勾配降下法, Adamの2通りの最適化手法を用いてパラメータを更新することとします。</p>
</div>
<div class="section" id="id3">
<h2>勾配降下法<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>勾配降下法とは、目的関数を微分した勾配の値のみを使ってパラメータを更新する方法です。<br />
たとえば,重み<span class="math notranslate nohighlight">\(W\)</span>の<span class="math notranslate nohighlight">\(i\)</span>番目を更新する際には<br />
<span class="math notranslate nohighlight">\(W_i := W_i - \eta \frac{\partial f}{\partial W_i}\)</span><br />
とします。(<span class="math notranslate nohighlight">\(f\)</span>は目的関数で、<span class="math notranslate nohighlight">\(\eta\)</span>は学習率(パラメータ更新のスケールを決めるパラメータ)です。)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calc_der</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">):</span>
    <span class="n">tdw</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">)</span>
    <span class="n">tdv</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">)</span>
    <span class="n">tdbs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">)</span>
    <span class="n">tdb0</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="c1">#以下の勾配の計算は、目的関数が二乗誤差かつ全データでの勾配の和を使用する場合にのみ正しい</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tV</span><span class="p">,</span> <span class="n">acf</span><span class="p">(</span><span class="n">tW</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">tbs</span><span class="p">)</span> <span class="p">)</span> <span class="o">+</span> <span class="n">tb0</span> <span class="o">-</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">tdb0</span> <span class="o">+=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">g</span>
        <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nhl</span><span class="p">):</span>                    
            <span class="n">tdv</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span>  <span class="o">+=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">g</span> <span class="o">*</span> <span class="n">acf</span><span class="p">(</span><span class="n">tW</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">tbs</span><span class="p">[</span><span class="n">jth</span><span class="p">])</span>
            <span class="n">tdw</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span>  <span class="o">+=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">g</span> <span class="o">*</span> <span class="n">tV</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span> <span class="o">*</span> <span class="n">acfder</span><span class="p">(</span><span class="n">tW</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">tbs</span><span class="p">[</span><span class="n">jth</span><span class="p">])</span> <span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">tdbs</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span> <span class="o">+=</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">g</span> <span class="o">*</span> <span class="n">tV</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span> <span class="o">*</span> <span class="n">acfder</span><span class="p">(</span><span class="n">tW</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">tbs</span><span class="p">[</span><span class="n">jth</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tdw</span><span class="p">,</span> <span class="n">tdv</span><span class="p">,</span> <span class="n">tdbs</span><span class="p">,</span> <span class="n">tdb0</span>

<span class="c1">#シグモイド関数の微分: 勾配の計算を具体的に求めるのに使う</span>
<span class="k">def</span> <span class="nf">sigmoid_der</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">)</span><span class="o">/</span> <span class="p">((</span><span class="mf">1.0</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>さてW,V,bs,b0の初期値での勾配の値は</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">acf</span> <span class="o">=</span> <span class="n">sigmoid</span>
<span class="n">acfder</span> <span class="o">=</span> <span class="n">sigmoid_der</span> <span class="c1">#sigmoid関数の微分sigmoid_derをacfderという名前で使う</span>
<span class="n">calc_der</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([ 5.21872673e-02, -8.03960749e+00,  1.83009108e+00,  1.91103332e+00,
         3.24927634e+00, -7.23670010e+00, -1.12232153e+00,  7.58282404e-03]),
 array([36.82875279, 29.24447765, 49.19261588,  9.67161219, 23.84412956,
        23.11524231, 35.19158249, 35.04412075]),
 array([ 2.14818071e-01, -3.23527933e+01,  9.04076394e+00,  8.00770445e+00,
         1.34159140e+01, -2.80674027e+01, -4.66782630e+00,  2.97730658e-02]),
 58.69466810466825)
</pre></div>
</div>
</div>
</div>
<p>と計算できるようになりました。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fitGD</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">,</span><span class="n">nepoch</span><span class="p">,</span><span class="n">eta</span><span class="p">,</span><span class="n">verbose</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nepoch</span><span class="p">):</span>
        <span class="n">tdw</span><span class="p">,</span><span class="n">tdv</span><span class="p">,</span><span class="n">tdbs</span><span class="p">,</span> <span class="n">tdb0</span> <span class="o">=</span> <span class="n">calc_der</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">)</span>
        <span class="n">tW</span> <span class="o">=</span> <span class="n">tW</span> <span class="o">-</span> <span class="n">eta</span> <span class="o">*</span> <span class="n">tdw</span>
        <span class="n">tV</span> <span class="o">=</span> <span class="n">tV</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">tdv</span>
        <span class="n">tbs</span> <span class="o">=</span>  <span class="n">tbs</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">tdbs</span>
        <span class="n">tb0</span> <span class="o">=</span> <span class="n">tb0</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">tdb0</span>        
        <span class="k">if</span> <span class="n">verbose</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;tloss =&quot;</span><span class="p">,</span> <span class="n">calc_tloss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">tdw</span><span class="p">,</span><span class="n">tdv</span><span class="p">,</span><span class="n">tdbs</span><span class="p">,</span> <span class="n">tdb0</span>
</pre></div>
</div>
</div>
</div>
<p>では実際に上の関数を使って、パラメータの値を更新してみましょう。<br />
(nhlの値に依りますが、ちょっぴり計算に時間がかかります)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">nepoch</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">acf</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">;</span> <span class="n">acfder</span><span class="o">=</span><span class="n">sigmoid_der</span>
<span class="n">verbose</span><span class="o">=</span><span class="mi">0</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mf">0.01</span> <span class="c1">#学習率(パラメータ更新のスケールを決めるパラメータ)</span>
<span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">dw</span><span class="p">,</span><span class="n">dv</span><span class="p">,</span><span class="n">dbs</span><span class="p">,</span><span class="n">db0</span><span class="o">=</span><span class="n">fitGD</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">,</span><span class="n">nepoch</span><span class="p">,</span><span class="n">eta</span><span class="p">,</span><span class="n">verbose</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>更新された重み・バイアス(W,V,bs,b0)を使って、データとの二乗誤差を計算してみると…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;学習後の二乗誤差&quot;</span><span class="p">,</span><span class="n">calc_tloss</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>学習後の二乗誤差 31.426829182338306
</pre></div>
</div>
</div>
</div>
<p>すると、さっきより小さくはなっていますが、そこまで二乗誤差が減っていません。</p>
<p>実際にplotしてみても</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span> 
<span class="n">yp</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">*</span><span class="n">xp</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">yp</span><span class="p">)):</span>
    <span class="n">yp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">W</span><span class="o">*</span><span class="n">xp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">bs</span><span class="p">))</span> <span class="o">+</span> <span class="n">b0</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Data&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">yp</span><span class="o">*</span><span class="n">ystd</span><span class="o">+</span><span class="n">ymean</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;ANN&quot;</span><span class="p">)</span> <span class="c1">## ニューラルネットワークの出力は標準化した値に対して学習されていることに注意</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Python_chapter_ArtificialNeuralNetwork_37_0.png" src="../_images/Python_chapter_ArtificialNeuralNetwork_37_0.png" />
</div>
</div>
<p>ほとんど学習が進んでいません…(絶望)</p>
<p>学習の様子を都度printしてみる(<code class="docutils literal notranslate"><span class="pre">verbose=1</span></code>に設定する)ことにして<br />
最初からやりなおしてみると…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">bs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>

<span class="n">nepoch</span><span class="o">=</span><span class="mi">20</span> <span class="c1">#20回だけ学習の様子を表示</span>
<span class="n">verbose</span><span class="o">=</span><span class="mi">1</span> 
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;学習前のloss&quot;</span><span class="p">,</span> <span class="n">calc_tloss</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">))</span>
<span class="c1">#学習</span>
<span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">dw</span><span class="p">,</span><span class="n">dv</span><span class="p">,</span><span class="n">dbs</span><span class="p">,</span><span class="n">db0</span><span class="o">=</span><span class="n">fitGD</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">,</span><span class="n">nepoch</span><span class="p">,</span><span class="n">eta</span><span class="p">,</span><span class="n">verbose</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>学習前のloss 61.29358546868393
0 tloss = 155.20176990047585
1 tloss = 636.6940976770327
2 tloss = 1982.0790483266553
3 tloss = 2056.051066857846
4 tloss = 75.1510373285995
5 tloss = 41.306942787588895
6 tloss = 40.230205073524374
7 tloss = 40.1956281449949
8 tloss = 40.19379266944327
9 tloss = 40.19298621925973
10 tloss = 40.19221490236367
11 tloss = 40.19144755457859
12 tloss = 40.19068317848521
13 tloss = 40.18992172293257
14 tloss = 40.189163166751285
15 tloss = 40.188407489902666
16 tloss = 40.18765467254862
17 tloss = 40.186904695016516
18 tloss = 40.186157537795744
19 tloss = 40.18541318153565
</pre></div>
</div>
</div>
</div>
<p>あるところからは、ほとんど学習が進んでいない事がわかります。</p>
<p>原因として考えられるのは</p>
<ul class="simple">
<li><p>loss functionをパラメータ(超)空間上にプロットした際にプラトーが存在する</p></li>
<li><p>最適化手法や学習率の設定が適切でない</p></li>
<li><p>初期値が悪い</p></li>
</ul>
<p>などがあります。</p>
<p>勾配降下法は、最もシンプルな勾配を使った最適化手法ですが、学習の途中で勾配がほとんど0になってしまって(勾配消失ともいう)、学習が進まなくなってしまう、といったことがよく起こります。</p>
<p>「勾配が小さいなら勾配にかける学習率を大きくすればええんとちゃいまんの…？」<br />
と思うかもしれませんが、学習率を単純に大きくしてしまうと、明後日の方向にパラメータを更新するせいで目的関数が発散してしまいます。(eta=0.1などとして試してみてください)</p>
<p>注) 勾配降下法を拡張した、データを部分的に使うことで学習が停滞することを防ぐ、確率的勾配降下法(Stochastic Gradient Descent; SGD)は現在もよく使われています。</p>
<p>以下では、Adamと呼ばれる別の最適化手法を試してみましょう。</p>
</div>
<div class="section" id="adam">
<h2>Adam<a class="headerlink" href="#adam" title="Permalink to this headline">¶</a></h2>
<p>Adamは、勾配降下法の様にその都度の勾配の情報だけを使うのではなく、
以前の勾配の情報も有効活用する手法です。</p>
<p>Adamは2014年に提唱された比較的新しい手法で、以降の機械学習の論文では、Adamが最もよく使われています。(*最も”良い”という意味では必ずしもありません)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">updateAdam</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">mt</span><span class="p">,</span><span class="n">vt</span><span class="p">,</span><span class="n">i</span><span class="p">,</span><span class="n">beta1</span><span class="p">,</span><span class="n">beta2</span><span class="p">,</span><span class="n">eps</span><span class="p">):</span>
    <span class="n">mhat</span> <span class="o">=</span> <span class="n">mt</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">beta1</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="n">vhat</span> <span class="o">=</span> <span class="n">vt</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">beta2</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">mhat</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">vhat</span> <span class="p">)</span><span class="o">+</span><span class="n">eps</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fitAdam</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">,</span><span class="n">nepoch</span><span class="p">,</span><span class="n">eta</span><span class="p">,</span><span class="n">verbose</span><span class="p">):</span>
    <span class="n">mts</span> <span class="o">=</span> <span class="p">[</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">]</span>
    <span class="n">vts</span>  <span class="o">=</span> <span class="p">[</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">nhl</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="p">]</span>
    <span class="c1">## Adamで使用するパラメータ</span>
    <span class="n">beta1</span> <span class="o">=</span> <span class="mf">0.9</span><span class="p">;</span> <span class="n">beta2</span> <span class="o">=</span> <span class="mf">0.999</span><span class="p">;</span> <span class="n">eps</span> <span class="o">=</span> <span class="mf">1.e-6</span>
    <span class="n">omb1</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">beta1</span><span class="p">;</span> <span class="n">omb2</span> <span class="o">=</span> <span class="mf">1.0</span><span class="o">-</span><span class="n">beta2</span>
    <span class="c1">## 最適化</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nepoch</span><span class="p">):</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="n">calc_der</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">)</span>   <span class="c1">### 勾配を計算するところまでは同じ。</span>
        <span class="k">for</span> <span class="n">n</span><span class="p">,</span><span class="n">mt</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mts</span><span class="p">):</span>
            <span class="n">mts</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">beta1</span> <span class="o">*</span> <span class="n">mt</span> <span class="o">+</span> <span class="n">omb1</span> <span class="o">*</span> <span class="n">tmp</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
            <span class="n">vts</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>  <span class="o">=</span> <span class="n">beta2</span> <span class="o">*</span> <span class="n">vts</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">+</span> <span class="n">omb2</span> <span class="o">*</span> <span class="p">(</span><span class="n">tmp</span><span class="p">[</span><span class="n">n</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1">### 重み・バイアスの更新</span>
        <span class="n">tW</span> <span class="o">+=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">updateAdam</span><span class="p">(</span><span class="n">tW</span><span class="p">,</span> <span class="n">mts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">vts</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">i</span><span class="p">,</span><span class="n">beta1</span><span class="p">,</span><span class="n">beta2</span><span class="p">,</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">tV</span>  <span class="o">+=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">updateAdam</span><span class="p">(</span><span class="n">tV</span><span class="p">,</span> <span class="n">mts</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">vts</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">i</span><span class="p">,</span><span class="n">beta1</span><span class="p">,</span><span class="n">beta2</span><span class="p">,</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">tbs</span> <span class="o">+=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span> <span class="n">updateAdam</span><span class="p">(</span><span class="n">tbs</span><span class="p">,</span><span class="n">mts</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">vts</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span><span class="n">i</span><span class="p">,</span><span class="n">beta1</span><span class="p">,</span><span class="n">beta2</span><span class="p">,</span><span class="n">eps</span><span class="p">)</span>
        <span class="n">tb0</span> <span class="o">+=</span> <span class="o">-</span><span class="n">eta</span> <span class="o">*</span>  <span class="p">(</span><span class="n">mts</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">beta1</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span> <span class="o">/</span> <span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">vts</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">/</span> <span class="p">(</span><span class="mf">1.0</span><span class="o">-</span><span class="n">beta2</span><span class="o">**</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s2">&quot;tloss =&quot;</span><span class="p">,</span> <span class="n">calc_tloss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span><span class="p">,</span><span class="n">acf</span><span class="p">))</span>        
    <span class="k">return</span> <span class="n">tW</span><span class="p">,</span><span class="n">tV</span><span class="p">,</span><span class="n">tbs</span><span class="p">,</span><span class="n">tb0</span>
</pre></div>
</div>
</div>
</div>
<p>それでは重みを初期化して、再び学習をしてみましょう</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">1234</span><span class="p">)</span> <span class="c1">## Gradient descentと同条件でスタートするためseedを固定</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">bs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">,</span><span class="n">nhl</span><span class="p">)</span>
<span class="n">b0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>

<span class="n">nepoch</span><span class="o">=</span><span class="mi">2000</span>
<span class="n">verbose</span><span class="o">=</span><span class="kc">False</span>
<span class="n">eta</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="n">acf</span> <span class="o">=</span> <span class="n">sigmoid</span> <span class="p">;</span> <span class="n">acfder</span> <span class="o">=</span><span class="n">sigmoid_der</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;学習前のloss&quot;</span><span class="p">,</span> <span class="n">calc_tloss</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">))</span>
<span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="o">=</span><span class="n">fitAdam</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">,</span><span class="n">acfder</span><span class="p">,</span><span class="n">nepoch</span><span class="p">,</span><span class="n">eta</span><span class="p">,</span><span class="n">verbose</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;学習後のloss&quot;</span><span class="p">,</span> <span class="n">calc_tloss</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span><span class="n">ny</span><span class="p">,</span><span class="n">W</span><span class="p">,</span><span class="n">V</span><span class="p">,</span><span class="n">bs</span><span class="p">,</span><span class="n">b0</span><span class="p">,</span><span class="n">acf</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>学習前のloss 61.29358546868393
学習後のloss [0.89838996]
</pre></div>
</div>
</div>
</div>
<p>さっきよりlossの値が小さくなっています。学習がうまく行ってそうですね。</p>
<p>グラフにしてみると…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span> 
<span class="n">yp</span> <span class="o">=</span> <span class="mf">0.0</span><span class="o">*</span><span class="n">xp</span> 
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">yp</span><span class="p">)):</span>
    <span class="n">yp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">W</span><span class="o">*</span><span class="n">xp</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">+</span><span class="n">bs</span><span class="p">))</span> <span class="o">+</span> <span class="n">b0</span> 
<span class="n">ytruth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">*</span><span class="n">xp</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">yt</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Data&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">yp</span><span class="o">*</span><span class="n">ystd</span><span class="o">+</span><span class="n">ymean</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;C01&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;ANN&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">ytruth</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s2">&quot;C02&quot;</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ground Truth&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Python_chapter_ArtificialNeuralNetwork_48_0.png" src="../_images/Python_chapter_ArtificialNeuralNetwork_48_0.png" />
</div>
</div>
<p>のように、データの特徴をそこそこうまく捉えたニューラルネットワークへと学習が進みました。</p>
<p>実際には、ニューラルネットワークの精度(良さ)は、前述のような検証データに対する汎化性能で評価します。</p>
<p>上で示した例では、3層のニューラルネットワークにデータからそれらしい関数を学習させてみました。</p>
<p>ニューラルネットワークの構造をより複雑化したりしながら、より複雑で高次元な回帰問題に応用したり、回帰問題だけではなく分類問題・画像生成・物体検知などなど、各種の楽しい実社会の問題に応用していきます。 (例: 第2回で説明した敵対的生成ネットワーク)</p>
</div>
<div class="section" id="id4">
<h2>最適化手法に関するまとめ<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>ニューラルネットワークの学習がうまく進むかどうかは一般に</p>
<ol class="simple">
<li><p>ネットワークの構造(アーキテクチャとも言ったりします)や活性化関数(とその微分)の持つ性質</p></li>
<li><p>最適化手法や手法内のパラメータ</p></li>
<li><p>重みやバイアスの初期値</p></li>
</ol>
<p>などに強く依存します。</p>
<p>1.に関して<br />
回帰問題における代表的な活性化関数としては
最近の傾向として、sigmoidよりも以下のReLU関数が使われることが多いです。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span> <span class="n">z</span>   

<span class="k">def</span> <span class="nf">relu_der</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
     <span class="k">return</span> <span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">*</span><span class="mf">1.0</span> 
     
<span class="c1">#いずれも、zが実数値でもnp.array型のベクトルでも対応可能な表式</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">##適当な区間のxの値を用意する</span>
<span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">yp_sigmoid</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">xp</span><span class="p">)</span>
<span class="n">yp_relu</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">xp</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">yp_sigmoid</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">yp_relu</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;ReLU&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Python_chapter_ArtificialNeuralNetwork_52_0.png" src="../_images/Python_chapter_ArtificialNeuralNetwork_52_0.png" />
</div>
</div>
<p>sigmoid関数はx-&gt;+∞で1.0, x=-∞で-1.0に漸近します。</p>
<p>一方でReLU関数はx=0までは0.0で、x&gt;0.0で、xとなるような関数です。</p>
<p>なぜReLUがよく使われる様になったかと言うと、<br />
(特に隠れ層の数が多い深層学習において)学習するにつれて勾配の値が小さくなって学習が進まない、
という問題を解決するためです。</p>
<p>それぞれの関数の微分を表示してみると</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">xp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">10.0</span><span class="p">,</span><span class="mf">10.0</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">yp_sigmoid</span> <span class="o">=</span> <span class="n">sigmoid_der</span><span class="p">(</span><span class="n">xp</span><span class="p">)</span>
<span class="n">yp_relu</span> <span class="o">=</span> <span class="n">relu_der</span><span class="p">(</span><span class="n">xp</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">ax1</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">yp_sigmoid</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;Sigmoid&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax2</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xp</span><span class="p">,</span><span class="n">yp_relu</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s2">&quot;ReLU&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Python_chapter_ArtificialNeuralNetwork_54_0.png" src="../_images/Python_chapter_ArtificialNeuralNetwork_54_0.png" />
</div>
</div>
<p>sigmoid関数は微分の値が最大で0.25なのに対して、ReLU関数では最大1.0となるため勾配の消失が起こりにくいのです。</p>
<p>問題ごとに何が最適なネットワーク構造だったり活性化関数なのかは、<br />
予め分かることはなく、試行錯誤が必要です。<br />
ここまでこの授業で勉強してきた皆さんは既に、<br />
「この試行錯誤自体を人力ではなくコンピュータにやらせる方法はないか」という点に思い至るのではないでしょうか?</p>
<p>これに関連したお話はベイズ最適化の回で説明します。</p>
<p>3.に関して</p>
<p>また、ネットワークの重みやバイアスをどのような値から始めるかに学習が依存する場合もあります。</p>
<p>というのも、今考えた３層のニューラルネットワークでは、<br />
重み<span class="math notranslate nohighlight">\(W\)</span>の学習に使う勾配の表式は、<span class="math notranslate nohighlight">\(V\)</span>に比例しています。</p>
<p>したがって単純に勾配の情報のみを使う最適化手法では、<br />
<span class="math notranslate nohighlight">\(V\)</span>の初期値を0に取ったり、学習の過程で偶然<span class="math notranslate nohighlight">\(V\)</span>の値が0に近くなってしまうと、<br />
<span class="math notranslate nohighlight">\(V\)</span>が更新されノンゼロの値を持つまで<span class="math notranslate nohighlight">\(W\)</span>の学習は始まりません。</p>
<p>どのような初期値を採用するべきかに関しても、予め知ることは一般にはできませんが、<br />
いくつかの特定の場合に関して、推奨される方法というのは存在しています。</p>
<p>例: ReLU関数を活性化関数に使うときはHeの初期値というものが推奨されている</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="Python_misc_numpy.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Numpyについて</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Python_chapter_BayesianOptimization.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ベイズ最適化による実験計画法</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          <div class="extra_footer">
            © Copyright 2020-2023 by 吉田 聡太 (Sota Yoshida). 本コンテンツは<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 ライセンス</a>の下に提供されています。 <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="クリエイティブ・コモンズ・ライセンス" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a>　ただし、資料中のコードセル部分は<a rel="license" href="https://opensource.org/licenses/MIT">MITライセンス</a>の下に提供されています。

          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>